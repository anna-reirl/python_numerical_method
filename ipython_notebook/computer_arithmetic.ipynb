{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Round-Off Error and Computer Arithmetic\n",
    "- Title: Methods of Numerical Analysis (Python)\n",
    "- Date: Oct/06/2015, Tuesday - Current\n",
    "- Author: Minwoo Bae (minubae.nyc@gmail.com)\n",
    "- Reference: Numerical Analysis - 10th Edition by Richard L. Burden, Douglas J. Faires, and Annette M. Burden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round-Off Error\n",
    "The arithmetic performed by a calculator or computer is different from the arithmetic in algebra and calculus courses. We would likely expect that we always have as true statements things such as $2+2=4$, $4 \\cdot 8 = 32$, and $(\\sqrt{3})^2 = 3$. However, with $\\mathit{computer}$ arithmetic, we expect exact results for $2+2=4$ and  $4 \\cdot 8 = 32$, but we will not have precisely $(\\sqrt{3})^2 = 3$. To understand why this is true, we must explore the world of finite-digit arithmetic.\n",
    "<br>\n",
    "<br>\n",
    "In our traditional mathematical world, we permit numbers with an infinite numbers of digits. The arithmetic we use in this world $\\mathit{defines}\\space\\sqrt{3}$ as that unique positive number that when multiplied by itself produces the integer 3. <span style=\"background-color:#FFFF00\">In the computational world, however, each representable number has only a fixed and finite number of digits. This means, for example, that only rational numbers--and not even all of these--can be represented exactly.</span> Since $\\sqrt{3}$ is not rational, it is given an approximate representation, one whose square will not be precisely 3, although it will likely be sufficiently close to 3 to be acceptable in most situations. In most cases, then, this machine arithmetic is satisfactory and passes without notice or concern, but at times problems arise because of this discrepancy.\n",
    "<br>\n",
    "<br>\n",
    "The error that is produced when a calculator or computer is used to perform real number calculations is called <b>round-off error</b>. It occurs because the arithmetic performed in a machine involved numbers with only <span style=\"background-color:#FFFF00\">a finite number of digits, with the result that calculations are performed with only approximate representations of the actual numbers.</span> In a computer, only a relatively small subset of the real number system is used for the representaion of all the real numbers. This subset contains only rational numbers, both positive and negative, and stores the fractional part, together with an exponential part. ( A computer utilizes a finite amount of storage for each number, similar to using a finite number of decimal places. Thus when the computer works a mathematical operation on two numbers, it essentially rounds each number, performs an exact computation on the rounded numbers, and rounds the answer. This is able to lead to round-off error.)\n",
    "### Example\n",
    "If Approximate $\\sqrt{7} \\approx 2.6$, then $\\sqrt{7} \\cdot \\sqrt{7} \\approx (2.6) \\cdot (2.6) = 6.76 \\approx 6.7\\ \\leftarrow$ (chopping trunctation) or $\\approx 6.8 \\leftarrow$ (rounding). <br>\n",
    "\n",
    "Although $\\sqrt{7} \\cdot \\sqrt{7}$ should be 7, we will get 6.7 or 6.7 via computing numbers on the computer.\n",
    "## Computer Storage of a Real Numbers\n",
    "### Binary number system:\n",
    "$1011_{2} = 1 \\cdot 2^3 + 0 \\cdot 2^2 + 1 \\cdot 2^1 + 1 \\cdot 2^0 = 8 + 0 + 2 + 1 = 11$\n",
    "\n",
    "### The Decimal system:\n",
    "$157_{10} = 1 \\cdot 10^2 + 5 \\cdot 10^1 + 7 \\cdot 10^0 = 100 + 50 + 7$\n",
    "\n",
    "## Binary Machine Numbers\n",
    "In 1985, the $\\mathrm{IEEE}$ ( Institute for Electrical and Electronic Engineers ) published a report call $\\mathit{Binary\\space Floating\\space Point\\space Arithmetic\\space Standard}$ 754-1985. An updated version was published in 2008 as $\\mathit{IEEE\\space 754-2008}$. This provides standards for binary and decimal floating point numbers, formats for data interchange, algorithms for rounding arithmetic operations, and the handling of exceptionis. Formats are specified for single, double, and extended precisions, and these standards are generally followed by all microcomputer manufactureres using floating-point hardware.\n",
    "<br>\n",
    "<br>\n",
    "A 64-bit ( binary digit ) representation is used for a real number. The first bit is a sign indicator, denoted $s$. This is followed by an 11-bit exponent, c, called the $\\mathbf{characteristic}$, and a 52-bit binary fraction, f, called the $\\mathbf{mantissa}$. The base for the exponent is 2.\n",
    "<br>\n",
    "<br>\n",
    "Since 52 binary digits correspond to between 16 to 17 decimal digits, we can assume that a number represented in this system has at least 16 decimal digits of precision. The exponent of 11 binary digits gives a range of $0$ to $2^{11} - 1 = 2047.$ However, using only positive integers for the exponent would not permit an adequate representation of numbers with small magnitude. To ensure that numbers with small magnitude are equally representable, <span style=\"background-color:#FFFF00\">1023 is subtracted from the characteristic, so the range of the exponent is actually from -1023 to 1024.</span> To save storage and provide a unique representation for each floating-point number, a normalization is imposed. Using this system gives a floating-point number of the form \n",
    "<br><br>\n",
    "$$(-1)^{s}2^{c-1023}(1+f).$$\n",
    "\n",
    "### Illustration\n",
    "Consider the machine number ( A 64-bit to represent a real number in the Computer )\n",
    "<br><br>\n",
    "$$\\overbrace{0}^{\\mathbf{s}} \\space \\underbrace{10000000011}_{11-bit: \\space \\mathbf{characteristic}} \\space \\overbrace{10111001000100000000000000000000000000000000000000000000000000}^{52-bit: \\space \\mathbf{mantissa}}$$\n",
    "<br><br>\n",
    "The leftmost bit is s = 0, which indicates that the number is positive. The next 11 bits, 10000000011, give the characteristic and are equivalent to the decimal number.\n",
    "<br><br>\n",
    "$$c = 1 \\cdot 2^{10} + 0 \\cdot 2^{9} + \\dots + 0 \\cdot 2^{2} + 1 \\cdot 2^{1} + 1 \\cdot 2^{0} = 1024 + 2 + 1 = 1027.$$\n",
    "<br><br>\n",
    "The exponential part of the number is, therefore, $2^{1027-1023} = 2^{4}.$ The final 52 bits specify that the mantissa is\n",
    "<br><br>\n",
    "$$f = 1 \\cdot \\bigg(\\frac{1}{2}\\bigg)^{2} + 1 \\cdot \\bigg(\\frac{1}{2}\\bigg)^{3} + 1 \\cdot \\bigg(\\frac{1}{2}\\bigg)^{4} + 1 \\cdot \\bigg(\\frac{1}{2}\\bigg)^{5} + 1 \\cdot \\bigg(\\frac{1}{2}\\bigg)^{8} + 1 \\cdot \\bigg(\\frac{1}{2}\\bigg)^{12}.$$\n",
    "<br><br>\n",
    "As a consequence, this machine number precisely represents the decimal number\n",
    "<br><br>\n",
    "$$(-1)^{s}2^{c-1023}(1+f) = (-1)^{0}2^{1027-1023}\\bigg(1+\\bigg(\\frac{1}{2}+\\frac{1}{8}+\\frac{1}{16}+\\frac{1}{32}+\\frac{1}{256}+\\frac{1}{4096}\\bigg)\\bigg) = 27.56640625.$$\n",
    "<br><br>\n",
    "However, the next smallest machine number is\n",
    "<br><br>\n",
    "$$0 \\space 10000000011 \\space 1011100100011111111111111111111111111111111111111111$$\n",
    "<br><br>\n",
    "and the next largest machine number is\n",
    "<br><br> \n",
    "$$0 \\space 10000000011 \\space 1011100100010000000000000000000000000000000000000001.$$\n",
    "<br><br>\n",
    "This means that our original machine number represents not only 27.56640625 but also half of the real numbers that are between 27.56640625 and the next smallest machine number as well as half the numbers between 27.56640625 and the next largest machine number. To be precise, it presents any real number in the interval\n",
    "<br><br>\n",
    "$$[27.5664062499999982236431605997495353221893310546875, \\space 27.5664062500000017763568394002504646778106689453125).$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 1.15\n",
    "Suppose that $p^{*}$ is an approximation to $p$. The $\\mathbf{actual \\space error}$ is $p-p^{*}$, the $\\mathbf{absoulute \\space error}$ is $|p-p^{*}|$, and the $\\mathbf{relative \\space error}$ is $\\frac{|p-p^{*}|}{|p|}$, provided that $p \\neq 0.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Error:  -0.7000000000000002\n",
      "Absolute Error:  0.7000000000000002\n",
      "Relative Error:  0.3500000000000001\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def actual_error(p, a_p):\n",
    "        return p - a_p\n",
    "    \n",
    "def absolute_error(p, a_p):\n",
    "        return math.fabs(p-a_p)\n",
    "\n",
    "def relative_error(p, a_p):\n",
    "    result = 0\n",
    "    if absolute_value(p) != 0:\n",
    "        result = absolute_error(p,a_p)/absolute_value(p)\n",
    "        return result\n",
    "    else:\n",
    "        print('error: absolute_value must not be equal to ',absolute_value(p))  \n",
    "\n",
    "print('Actual Error: ',actual_error(2, 2.7))\n",
    "print('Absolute Error: ',absolute_error(2, 2.7))\n",
    "print('Relative Error: ',relative_error(2, 2.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
